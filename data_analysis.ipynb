{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "from  geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "import os\n",
    "data_path = 'output'\n",
    "field_to_count='id' # Field that contains a value (not null) in each row.\n",
    "percentage = 'percentage (%)'\n",
    "count = 'count'\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "project_crs = 'epsg:3857'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "        id                  date         date_reported            type  \\\n0        4  2021-05-27T22:34:00Z  2021-05-28T22:50:36Z        incident   \n1        7  2021-05-29T19:46:42Z  2021-05-29T20:01:09Z        incident   \n2        8  2021-05-31T17:54:58Z  2021-05-31T18:00:16Z         amenity   \n3       16  2021-06-04T17:31:46Z  2021-06-04T17:56:33Z        incident   \n4       17  2021-06-04T21:35:00Z  2021-06-04T21:41:11Z         amenity   \n...    ...                   ...                   ...             ...   \n1383  1987  2022-11-27T18:00:00Z  2022-12-04T20:03:10Z  hazard-concern   \n1384  1988  2022-12-04T19:55:30Z  2022-12-04T20:05:26Z  hazard-concern   \n1385  1989  2022-12-04T19:55:30Z  2022-12-04T20:08:21Z         amenity   \n1386  1990  2022-12-04T19:55:30Z  2022-12-04T20:11:31Z         amenity   \n1387  1991  2022-12-04T19:55:30Z  2022-12-04T20:13:56Z         amenity   \n\n      birth_year       gender         race disability disability_type  \\\n0           1971       female        white         no             NaN   \n1           2000  no-response  no-response         no             NaN   \n2           1982         male        white         no             NaN   \n3           1982         male        white         no             NaN   \n4           1993       female        white         no             NaN   \n...          ...          ...          ...        ...             ...   \n1383        1975         male        black         no             NaN   \n1384        1975       female        black         no             NaN   \n1385        1986         male        white         no             NaN   \n1386        1962         male       latino         no             NaN   \n1387        1998       female   indigenous        yes       cognitive   \n\n     mobility_aid  ...        lat gender_class age  age_class  \\\n0     no response  ...  48.459019        Women  50      45-54   \n1     no response  ...  48.433674  No Response  21      18-24   \n2     no response  ...  49.288649          Men  39      35-44   \n3     no response  ...  49.281230          Men  39      35-44   \n4     no response  ...  49.263620        Women  28      25-34   \n...           ...  ...        ...          ...  ..        ...   \n1383  no response  ...  45.497378          Men  47      45-54   \n1384  no response  ...  45.501452        Women  47      45-54   \n1385  no response  ...  45.496891          Men  36      35-44   \n1386  no response  ...  45.504402          Men  60      55-64   \n1387           no  ...  45.504698        Women  24      18-24   \n\n      mobility_aid_type_class disability_type_class                   pacific  \\\n0                 No response                  None 2021-05-27 15:34:00-07:00   \n1                 No response                  None 2021-05-29 12:46:42-07:00   \n2                 No response                  None 2021-05-31 10:54:58-07:00   \n3                 No response                  None 2021-06-04 10:31:46-07:00   \n4                 No response                  None 2021-06-04 14:35:00-07:00   \n...                       ...                   ...                       ...   \n1383              No response                  None 2022-11-27 10:00:00-08:00   \n1384              No response                  None 2022-12-04 11:55:30-08:00   \n1385              No response                  None 2022-12-04 11:55:30-08:00   \n1386              No response                  None 2022-12-04 11:55:30-08:00   \n1387                     None             Cognitive 2022-12-04 11:55:30-08:00   \n\n     hour       day day_val  \n0      15  Thursday       3  \n1      12  Saturday       5  \n2      10    Monday       0  \n3      10    Friday       4  \n4      14    Friday       4  \n...   ...       ...     ...  \n1383   10    Sunday       6  \n1384   11    Sunday       6  \n1385   11    Sunday       6  \n1386   11    Sunday       6  \n1387   11    Sunday       6  \n\n[1388 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date</th>\n      <th>date_reported</th>\n      <th>type</th>\n      <th>birth_year</th>\n      <th>gender</th>\n      <th>race</th>\n      <th>disability</th>\n      <th>disability_type</th>\n      <th>mobility_aid</th>\n      <th>...</th>\n      <th>lat</th>\n      <th>gender_class</th>\n      <th>age</th>\n      <th>age_class</th>\n      <th>mobility_aid_type_class</th>\n      <th>disability_type_class</th>\n      <th>pacific</th>\n      <th>hour</th>\n      <th>day</th>\n      <th>day_val</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>2021-05-27T22:34:00Z</td>\n      <td>2021-05-28T22:50:36Z</td>\n      <td>incident</td>\n      <td>1971</td>\n      <td>female</td>\n      <td>white</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>no response</td>\n      <td>...</td>\n      <td>48.459019</td>\n      <td>Women</td>\n      <td>50</td>\n      <td>45-54</td>\n      <td>No response</td>\n      <td>None</td>\n      <td>2021-05-27 15:34:00-07:00</td>\n      <td>15</td>\n      <td>Thursday</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>2021-05-29T19:46:42Z</td>\n      <td>2021-05-29T20:01:09Z</td>\n      <td>incident</td>\n      <td>2000</td>\n      <td>no-response</td>\n      <td>no-response</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>no response</td>\n      <td>...</td>\n      <td>48.433674</td>\n      <td>No Response</td>\n      <td>21</td>\n      <td>18-24</td>\n      <td>No response</td>\n      <td>None</td>\n      <td>2021-05-29 12:46:42-07:00</td>\n      <td>12</td>\n      <td>Saturday</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>2021-05-31T17:54:58Z</td>\n      <td>2021-05-31T18:00:16Z</td>\n      <td>amenity</td>\n      <td>1982</td>\n      <td>male</td>\n      <td>white</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>no response</td>\n      <td>...</td>\n      <td>49.288649</td>\n      <td>Men</td>\n      <td>39</td>\n      <td>35-44</td>\n      <td>No response</td>\n      <td>None</td>\n      <td>2021-05-31 10:54:58-07:00</td>\n      <td>10</td>\n      <td>Monday</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16</td>\n      <td>2021-06-04T17:31:46Z</td>\n      <td>2021-06-04T17:56:33Z</td>\n      <td>incident</td>\n      <td>1982</td>\n      <td>male</td>\n      <td>white</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>no response</td>\n      <td>...</td>\n      <td>49.281230</td>\n      <td>Men</td>\n      <td>39</td>\n      <td>35-44</td>\n      <td>No response</td>\n      <td>None</td>\n      <td>2021-06-04 10:31:46-07:00</td>\n      <td>10</td>\n      <td>Friday</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>2021-06-04T21:35:00Z</td>\n      <td>2021-06-04T21:41:11Z</td>\n      <td>amenity</td>\n      <td>1993</td>\n      <td>female</td>\n      <td>white</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>no response</td>\n      <td>...</td>\n      <td>49.263620</td>\n      <td>Women</td>\n      <td>28</td>\n      <td>25-34</td>\n      <td>No response</td>\n      <td>None</td>\n      <td>2021-06-04 14:35:00-07:00</td>\n      <td>14</td>\n      <td>Friday</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1383</th>\n      <td>1987</td>\n      <td>2022-11-27T18:00:00Z</td>\n      <td>2022-12-04T20:03:10Z</td>\n      <td>hazard-concern</td>\n      <td>1975</td>\n      <td>male</td>\n      <td>black</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>no response</td>\n      <td>...</td>\n      <td>45.497378</td>\n      <td>Men</td>\n      <td>47</td>\n      <td>45-54</td>\n      <td>No response</td>\n      <td>None</td>\n      <td>2022-11-27 10:00:00-08:00</td>\n      <td>10</td>\n      <td>Sunday</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1384</th>\n      <td>1988</td>\n      <td>2022-12-04T19:55:30Z</td>\n      <td>2022-12-04T20:05:26Z</td>\n      <td>hazard-concern</td>\n      <td>1975</td>\n      <td>female</td>\n      <td>black</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>no response</td>\n      <td>...</td>\n      <td>45.501452</td>\n      <td>Women</td>\n      <td>47</td>\n      <td>45-54</td>\n      <td>No response</td>\n      <td>None</td>\n      <td>2022-12-04 11:55:30-08:00</td>\n      <td>11</td>\n      <td>Sunday</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1385</th>\n      <td>1989</td>\n      <td>2022-12-04T19:55:30Z</td>\n      <td>2022-12-04T20:08:21Z</td>\n      <td>amenity</td>\n      <td>1986</td>\n      <td>male</td>\n      <td>white</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>no response</td>\n      <td>...</td>\n      <td>45.496891</td>\n      <td>Men</td>\n      <td>36</td>\n      <td>35-44</td>\n      <td>No response</td>\n      <td>None</td>\n      <td>2022-12-04 11:55:30-08:00</td>\n      <td>11</td>\n      <td>Sunday</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1386</th>\n      <td>1990</td>\n      <td>2022-12-04T19:55:30Z</td>\n      <td>2022-12-04T20:11:31Z</td>\n      <td>amenity</td>\n      <td>1962</td>\n      <td>male</td>\n      <td>latino</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>no response</td>\n      <td>...</td>\n      <td>45.504402</td>\n      <td>Men</td>\n      <td>60</td>\n      <td>55-64</td>\n      <td>No response</td>\n      <td>None</td>\n      <td>2022-12-04 11:55:30-08:00</td>\n      <td>11</td>\n      <td>Sunday</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1387</th>\n      <td>1991</td>\n      <td>2022-12-04T19:55:30Z</td>\n      <td>2022-12-04T20:13:56Z</td>\n      <td>amenity</td>\n      <td>1998</td>\n      <td>female</td>\n      <td>indigenous</td>\n      <td>yes</td>\n      <td>cognitive</td>\n      <td>no</td>\n      <td>...</td>\n      <td>45.504698</td>\n      <td>Women</td>\n      <td>24</td>\n      <td>18-24</td>\n      <td>None</td>\n      <td>Cognitive</td>\n      <td>2022-12-04 11:55:30-08:00</td>\n      <td>11</td>\n      <td>Sunday</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>1388 rows Ã— 24 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"wrm_demographics_2022-12-05.csv\"\n",
    "ir_fields =['description','geometry',]\n",
    "data_0 = pd.read_csv(path)\n",
    "data = data_0.drop(ir_fields,axis=1)\n",
    "# date to day and hour\n",
    "date = pd.to_datetime((data['date'].str.replace('Z','').str.replace('T',' ')))\n",
    "# date in pacific time\n",
    "act_time = 'pacific'\n",
    "data[act_time] = pd.DatetimeIndex(date).tz_localize('GMT').tz_convert(tz='US/Pacific')\n",
    "hour,day,day_val  = 'hour','day','day_val'\n",
    "data[hour],data[day], data[day_val] = data['pacific'].dt.hour, data['pacific'].dt.day_name(),data['pacific'].dt.dayofweek\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def bivariate_analysis(data_to_group:(GeoDataFrame, DataFrame), main_vars:list, secondary_vars:list, field_to_store:str):\n",
    "    r\"\"\"\n",
    "    It goes over the dictionary and calculate the cross relation between the variable inside\n",
    "    :param is_staty: to use data from other data saved on the disk\n",
    "    :param data_to_group: data to work on\n",
    "    :param field_to_store: which field to retain after groupby and counting\n",
    "    :param name_analysis: it is used to create new folder if necessary\n",
    "    :param main_vars:\n",
    "    :param secondary_vars:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for main_var in main_vars:\n",
    "        print(f'\\n{main_var}')\n",
    "        new_tables_data = {}\n",
    "        data1 = data_to_group[~data_to_group[main_var].isin(['No Response', 'no response'])].dropna(subset= main_var)\n",
    "        for other in secondary_vars:\n",
    "            print(f'{other}\\t',end=\"\")\n",
    "            data2 = data1[~data_to_group[other].isin(['No Response', 'no response'])].dropna(subset=other)\n",
    "            sum_field = data2.groupby(main_var).count()[field_to_store].rename('count')\n",
    "            # GroupBy two questions (one of which is main_var)\n",
    "            table_00 = DataFrame(data2.groupby([main_var, other]).count()[field_to_store].rename(''))\n",
    "            # Get the data in readable structure\n",
    "            table_0 =table_00.unstack(fill_value=0)\n",
    "            # Clean columns and index\n",
    "            table_0.columns = table_0.columns.droplevel()\n",
    "\n",
    "            # get percentage (questions variables for each group)\n",
    "            old_columns =table_0.columns\n",
    "            table_2 = table_0.copy()\n",
    "            table_2[old_columns +' (%)'] = round(table_0.div(sum_field, axis=0) * 100, 1).astype(str) +'%'\n",
    "            table_2['sum_field'] = sum_field\n",
    "            new_tables_data[f'{other}'] =table_2.sort_values(by='sum_field',ascending=False)\n",
    "        with pd.ExcelWriter(f\"{data_path}/{main_var}.xlsx\") as writer:\n",
    "            [item[1].to_excel(writer, sheet_name=item[0]) for item in new_tables_data.items()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hour\n",
      "type\tfeature_type\tfeature_subtype\t\n",
      "day\n",
      "type\tfeature_type\tfeature_subtype\t\n",
      "gender_class\n",
      "type\tfeature_type\tfeature_subtype\t\n",
      "disability\n",
      "type\tfeature_type\tfeature_subtype\t\n",
      "disability_type\n",
      "type\tfeature_type\tfeature_subtype\t\n",
      "mobility_aid\n",
      "type\tfeature_type\tfeature_subtype\t\n",
      "age_class\n",
      "type\tfeature_type\tfeature_subtype\t\n",
      "disability_type_class\n",
      "type\tfeature_type\tfeature_subtype\t"
     ]
    }
   ],
   "source": [
    "dict_main =['hour','day','gender_class','disability','disability_type','mobility_aid','age_class','disability_type_class']\n",
    "other_data = ['type', 'feature_type', 'feature_subtype']\n",
    "bivariate_analysis(data_to_group=data, main_vars=dict_main, secondary_vars=other_data, field_to_store='id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### make spatial data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "is_export = False\n",
    "crs = 'EPSG:4326'\n",
    "spatial_folder = 'shpfiles'\n",
    "spatial_data = GeoDataFrame(data, geometry=data.apply(lambda x:Point(x['lon'],x['lat']),axis =1),crs=crs)\n",
    "if is_export:\n",
    "    spatial_data.to_file(f'{spatial_folder}/WRM.shp')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def add_city_name(city_name:str):\n",
    "    r\"\"\"\n",
    "    Upload the city's shp file from the disk and add its name by s_join to the corresponding points.\n",
    "    :param city_name:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    city  = gpd.read_file(f'{spatial_folder}/{city_name}.shp').to_crs(crs)\n",
    "    s_data = spatial_data.sjoin(city)\n",
    "    s_data['city'] =city_name\n",
    "    return s_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Upload city boundary polygons\n",
    "data_with_city_name = pd.concat([add_city_name(name) for name in ['Ottawa','victoria']])\n",
    "data_with_city_name = data_with_city_name[list(spatial_data.columns) + ['city']].to_crs(project_crs)\n",
    "\n",
    "# Export to shp file\n",
    "data_with_city_name[act_time]= data_with_city_name[act_time].astype(str)\n",
    "data_with_city_name.to_file(f'{spatial_folder}/Ottawa_victoria.shp')\n",
    "data_with_city_name[data_with_city_name['city']=='victoria'].to_file(f'{spatial_folder}/victoria_pnt.shp')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# Create new colum which present the informaion in col_to_encode as numeric number\n",
    "col_to_encode= 'type'\n",
    "data_with_city_name[f'en_{col_to_encode}'] = data_with_city_name[col_to_encode].astype('category').cat.codes\n",
    "data_with_city_name[data_with_city_name['city']=='victoria'].to_file(f'{spatial_folder}/victoria_pnt.shp')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "city\n",
      "type\tfeature_type\tfeature_subtype\t"
     ]
    }
   ],
   "source": [
    "dict_main =['city']\n",
    "other_data = ['type', 'feature_type', 'feature_subtype']\n",
    "bivariate_analysis(data_to_group=data_with_city_name, main_vars=dict_main, secondary_vars=other_data, field_to_store='id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test area"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "city\n",
      "type\tfeature_type\tfeature_subtype\t"
     ]
    }
   ],
   "source": [
    "main_vars= dict_main\n",
    "data_to_group=data_with_city_name\n",
    "field_to_store = 'id'\n",
    "secondary_vars = other_data\n",
    "for main_var in main_vars:\n",
    "    print(f'\\n{main_var}')\n",
    "    new_tables_data = {}\n",
    "    data1 = data_to_group[~data_to_group[main_var].isin(['No Response', 'no response'])]\n",
    "    sum_field = data1.groupby(main_var).count()[field_to_store].rename('count')\n",
    "    for other in secondary_vars:\n",
    "        print(f'{other}\\t', end=\"\")\n",
    "        data2 = data1[~data_to_group[other].isin(['No Response', 'no response'])]\n",
    "        # GroupBy two questions (one of which is main_var)\n",
    "        table_00 = DataFrame(data2.groupby([main_var, other]).count()[field_to_store].rename(''))\n",
    "        # Get the data in readable structure\n",
    "        table_0 = table_00.unstack(fill_value=0)\n",
    "        # Clean columns and index\n",
    "        table_0.columns = table_0.columns.droplevel()\n",
    "\n",
    "        # get percentage (questions variables for each group)\n",
    "        old_columns = table_0.columns\n",
    "        table_2 = table_0.copy()\n",
    "        table_2[old_columns + ' (%)'] = round(table_0.div(sum_field, axis=0) * 100, 1)\n",
    "        table_2['sum_field'] = sum_field\n",
    "        new_tables_data[f'{other}'] = table_2.sort_values(by='sum_field', ascending=False)\n",
    "    with pd.ExcelWriter(f\"{data_path}/{main_var}.xlsx\") as writer:\n",
    "        [item[1].to_excel(writer, sheet_name=item[0]) for item in new_tables_data.items()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "type      amenity  hazard-concern  incident\ncity                                       \nOttawa         64             112         7\nvictoria      231             367       112",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>type</th>\n      <th>amenity</th>\n      <th>hazard-concern</th>\n      <th>incident</th>\n    </tr>\n    <tr>\n      <th>city</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Ottawa</th>\n      <td>64</td>\n      <td>112</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>victoria</th>\n      <td>231</td>\n      <td>367</td>\n      <td>112</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "          count\ncity           \nOttawa      183\nvictoria    710",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>city</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Ottawa</th>\n      <td>183</td>\n    </tr>\n    <tr>\n      <th>victoria</th>\n      <td>710</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_field\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}